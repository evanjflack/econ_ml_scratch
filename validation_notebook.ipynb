{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Econ ML Validation\n",
    "\n",
    "**Authors:** Evan Flack and Amar Venugopal\n",
    "\n",
    "**Description:** This notebook provides an example use-case for calibration scores for CATE models. Currently, it implements two scores: a linear regression score (Chernozhukov et al., 2022) and a calibration score (Dwivedi et al., 2020)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "import joblib\n",
    "\n",
    "from datasets import fetch_data_generator\n",
    "from myflaml import auto_reg, auto_clf\n",
    "# from validation import DRLinear, cal_scorer\n",
    "# from DRlinear import DRLinear\n",
    "# from cal_scorer import cal_scorer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Notebook options\n",
    "# Set as true if you have already pre-hyper-tuned the nuisance and/or dr learner models\n",
    "pre_tuned_n = True\n",
    "pre_tuned_dr = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prep Data\n",
    "\n",
    "#### Semi-synthetic data on 401k savings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "## For semi-synthetic data generation\n",
    "data = '401k'\n",
    "semi_synth = False # Whether true outcome y should be replaced by a fake outcome from a known CEF\n",
    "simple_synth = True # Whether the true CEF of the fake y should be simple or fitted from data\n",
    "max_depth = 2 # max depth of random forest during for semi-synthetic model fitting\n",
    "scale = .2 # magnitude of noise in semi-synthetic data\n",
    "\n",
    "np.random.seed(712)\n",
    "def simple_true_cef(D, X): # simple CEF of the outcome for semi-synthetic data\n",
    "    return .5 * np.array(X)[:, 1] * D + np.array(X)[:, 1]\n",
    "\n",
    "\n",
    "get_data, abtest, true_cef, true_cate = fetch_data_generator(data=data, semi_synth=semi_synth,\n",
    "                                                             simple_synth=simple_synth,\n",
    "                                                             scale=scale, true_f=simple_true_cef,\n",
    "                                                             max_depth=max_depth)\n",
    "X, D, y, groups = get_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Split into training (X), validation (Xval), and test (Xtest) sub-samples\n",
    "X, Xval, D, Dval, y, yval = train_test_split(X, D, y, train_size=.6, shuffle=True, random_state=123)\n",
    "Xval, Xtest, Dval, Dtest, yval, ytest = train_test_split(Xval, Dval, yval, train_size=.5, shuffle=True, random_state=123)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune Nuisance Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "time_budget = 120\n",
    "groups = None\n",
    "n_splits = 5\n",
    "split_type = 'auto'\n",
    "verbose = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model_reg = auto_reg(X, y, groups=groups, n_splits=n_splits, split_type=split_type,\n",
    "#                          verbose=verbose, time_budget=time_budget)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# joblib.dump([model_t(), model_reg(), model_reg_zero(), model_reg_one()], 'nuisance.jbl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Tune hyper-parameters/find best prediction method (restricted here to xgboost)\n",
    "if pre_tuned_n:\n",
    "    mt, mreg, mreg_zero, mreg_one = joblib.load('nuisance.jbl')\n",
    "    model_t = lambda: clone(mt)\n",
    "    model_reg = lambda: clone(mreg)\n",
    "    model_reg_zero = lambda: clone(mreg_zero)\n",
    "    model_reg_one = lambda: clone(mreg_one)\n",
    "\n",
    "else:\n",
    "    model_reg_zero = auto_reg(X[D==0], y[D==0], groups=groups, n_splits=n_splits, split_type=split_type,\n",
    "                              verbose=verbose, time_budget=time_budget)\n",
    "    model_reg_one = auto_reg(X[D==1], y[D==1], groups=groups, n_splits=n_splits, split_type=split_type,\n",
    "                             verbose=verbose, time_budget=time_budget)\n",
    "    model_t = auto_clf(X, D, groups=groups, n_splits=n_splits, split_type=split_type,\n",
    "                       verbose=verbose, time_budget=time_budget)\n",
    "\n",
    "    joblib.dump([model_t(), model_reg_zero(), model_reg_one()], 'nuisance.jbl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get OOS Predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.09591588, 0.68718326, 0.18263313, ..., 0.33677948, 0.18915652,\n       0.33222175], dtype=float32)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t().fit(X, D).predict(Xval)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123)\n",
    "# splits = list(cv.split(X, D))\n",
    "#\n",
    "# n = X.shape[0]\n",
    "# reg_preds = np.zeros(n)\n",
    "# reg_zero_preds = np.zeros(n)\n",
    "# reg_one_preds = np.zeros(n)\n",
    "# reg_preds_t = np.zeros(n)\n",
    "# reg_zero_preds_t = np.zeros(n)\n",
    "# reg_one_preds_t = np.zeros(n)\n",
    "#\n",
    "# DX = np.column_stack((D, X))\n",
    "# for train, test in splits:\n",
    "#     reg_zero = model_reg_zero().fit(X.iloc[train][D[train]==0], y[train][D[train]==0])\n",
    "#     reg_one = model_reg_one().fit(X.iloc[train][D[train]==1], y[train][D[train]==1])\n",
    "#     reg_zero_preds_t[test] = reg_zero.predict(X.iloc[test])\n",
    "#     reg_one_preds_t[test] = reg_one.predict(X.iloc[test])\n",
    "#     reg_preds_t[test] = reg_zero_preds_t[test] * (1 - D[test]) + reg_one_preds_t[test] * D[test]\n",
    "#\n",
    "# prop_preds = cross_val_predict(model_t(), X, D, cv=splits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DR Meta-Learner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Subset of features used for treatment effect heterogeneity\n",
    "hetero_feats = ['inc']\n",
    "Z, Zval, Ztest = X[hetero_feats], Xval[hetero_feats], Xtest[hetero_feats]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Calculate DR outcomes\n",
    "# dr_preds = reg_one_preds_t - reg_zero_preds_t\n",
    "# dr_preds += (y - reg_preds_t) * (D - prop_preds) / np.clip(prop_preds * (1 - prop_preds), .01, np.inf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Predict DR outcomes using Z\n",
    "if not pre_tuned_dr:\n",
    "    model_final_fn = lambda Z, y: auto_reg(Z, y, groups=groups, n_splits=n_splits, split_type=split_type,\n",
    "                                           verbose=verbose, time_budget=time_budget)\n",
    "    drlearner_best = model_final_fn(Z, dr_preds)\n",
    "    joblib.dump(drlearner_best(), 'drlearner.jbl')\n",
    "\n",
    "drlearner = joblib.load('drlearner.jbl')\n",
    "# drlearner = drlearner_best.fit(Z, dr_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Fit nuisance models using the entire training sample\n",
    "# reg_zero = model_reg_zero().fit(X[D == 0], y[D == 0])\n",
    "# reg_one = model_reg_one().fit(X[D == 1], y[D == 1])\n",
    "# reg_t = model_t().fit(X, D)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.sort(np.array([0, 3, 2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.tools import add_constant\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "\n",
    "class DRtester:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        reg_outcome,\n",
    "        reg_t\n",
    "    ):\n",
    "        self.reg_outcome = reg_outcome\n",
    "        self.reg_t = reg_t\n",
    "\n",
    "    # Fits nusisance and CATE\n",
    "    def fit(\n",
    "        self,\n",
    "        reg_cate,\n",
    "        Xval,\n",
    "        Dval,\n",
    "        yval,\n",
    "        Zval,\n",
    "        Xtrain = None,\n",
    "        Dtrain = None,\n",
    "        ytrain = None,\n",
    "        Ztrain = None):\n",
    "\n",
    "        if (Xtrain is not None) & (Dtrain is not None) & (ytrain is not None) & (Ztrain is not None):\n",
    "            reg_preds_train, prop_preds_train = self.fit_nuisance_cv(Xtrain, Dtrain, ytrain)\n",
    "            self.dr_train = self.calculate_dr_outcomes(Dtrain, ytrain, reg_preds_train, prop_preds_train)\n",
    "\n",
    "            reg_preds_val, prop_preds_val = self.fit_nuisance_train(Xtrain, Dtrain, ytrain, Xval, Dval)\n",
    "            self.dr_val = self.calculate_dr_outcomes(Dval, yval, reg_preds_val, prop_preds_val)\n",
    "\n",
    "            self.cate_preds_val = self.fit_cate_train(reg_cate, Ztrain, Zval)\n",
    "            # self.cate_preds_train = self.fit_cate_cv(reg_cate, self.dr_train, Ztrain, Dtrain)\n",
    "\n",
    "        else:\n",
    "            reg_preds_val, prop_preds_val = self.fit_nuisance_cv(self.reg_outcome, self.reg_t, Xval, Dval, yval)\n",
    "            self.dr_train = self.calculate_dr_outcomes(Dtrain, ytrain, reg_preds_val, prop_preds_val)\n",
    "            self.cate_preds_val =  self.fit_cate_cv(reg_cate, self.dr_val, Zval, Dval)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def evaluate_blp(self):\n",
    "        self.res = OLS(self.dr_val, add_constant(self.cate_preds_val)).fit()\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Fits nuisance in train, predicts in validation\n",
    "    def fit_nuisance_train(self, Xtrain, Dtrain, ytrain, Xval, Dval):\n",
    "\n",
    "        # Possible treatments (need to allow more than 2)\n",
    "        tmts = np.sort(np.unique(D))\n",
    "        n = Xval.shape[0]\n",
    "        k = len(tmts)\n",
    "        reg_preds = np.zeros((n, k))\n",
    "        for i in range(k):\n",
    "            reg_outcome_fitted = self.reg_outcome().fit(Xtrain[Dtrain == tmts[i]], ytrain[Dtrain == tmts[i]])\n",
    "            reg_preds[:, i] = reg_outcome_fitted.predict(Xval)\n",
    "\n",
    "        reg_t_fitted = self.reg_t().fit(Xtrain, Dtrain)\n",
    "        prop_preds = reg_t_fitted.predict(Xval)\n",
    "\n",
    "        return reg_preds, prop_preds\n",
    "\n",
    "    # CV nuisance predictions\n",
    "    def fit_nuisance_cv(self, X, D, y, n_splits = 5, shuffle = True, random_state = 712):\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "        splits = list(cv.split(X, D))\n",
    "\n",
    "        tmts = np.sort(np.unique(D))\n",
    "        n = X.shape[0]\n",
    "        k = len(tmts)\n",
    "        reg_preds = np.zeros((n, k))\n",
    "\n",
    "        for i in range(k):\n",
    "            for train, test in splits:\n",
    "                reg_outcome_fitted = self.reg_outcome().fit(X.iloc[train][D[train] == tmts[i]], y[train][D[train] == tmts[i]])\n",
    "                reg_preds[test, i] = reg_outcome_fitted.predict(X.iloc[test])\n",
    "\n",
    "        prop_preds = cross_val_predict(model_t(), X, D, cv=splits)\n",
    "\n",
    "        return reg_preds, prop_preds\n",
    "\n",
    "    # Calculates DR outcomes\n",
    "    def calculate_dr_outcomes(\n",
    "            self,\n",
    "            D,\n",
    "            y,\n",
    "            reg_preds,\n",
    "            prop_preds\n",
    "    ):\n",
    "\n",
    "        reg_preds_chosen = np.sum(reg_preds * np.column_stack((D, 1 - D)), axis = 1)\n",
    "\n",
    "        # Calculate doubly-robust outcome\n",
    "        dr = reg_preds[:, 1] - reg_preds[:, 0]\n",
    "        # Reiz representation, clip denominator at 0.01\n",
    "        reisz = (D - prop_preds) / np.clip(prop_preds * (1 - prop_preds), .01, np.inf)\n",
    "        dr += (y - reg_preds_chosen) * reisz\n",
    "\n",
    "        return dr\n",
    "\n",
    "    # Fits CATE in training, predicts in validation\n",
    "    def fit_cate_train(self, reg_cate, Ztrain, Zval):\n",
    "\n",
    "        reg_cate_fitted = reg_cate.fit(Ztrain, self.dr_train)\n",
    "        cate_preds = reg_cate_fitted.predict(Zval)\n",
    "\n",
    "        return cate_preds\n",
    "\n",
    "    # CV prediction of CATEs\n",
    "    def fit_cate_cv(reg_cate, dr, Z, D, shuffle = True, random_state = 712):\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "        splits = list(cv.split(Z, D))\n",
    "\n",
    "        n = X.shape[0]\n",
    "        cate_preds = np.zeros(n)\n",
    "\n",
    "        for train, test in splits:\n",
    "            reg_cate_fitted = reg_cate.fit(Z.iloc[train], dr[train])\n",
    "            cate_preds[test] = reg_cate_fitted.predict(Z.iloc[test])\n",
    "\n",
    "        return cate_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[597.11154873   0.9053472 ]\n"
     ]
    }
   ],
   "source": [
    "my_dr_test = DRtester(model_reg, model_t)\n",
    "my_dr_test = my_dr_test.fit(drlearner, Xval, Dval, yval, Zval, X, D, y, Z)\n",
    "my_dr_test = my_dr_test.evaluate_blp()\n",
    "print(my_dr_test.res.params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[597.11154873   0.9053472 ]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_drlinear = DRLinear(drlearner, reg_zero, reg_one, reg_t)\n",
    "my_drlinear = my_drlinear.fit(Xval, Dval, yval, Zval)\n",
    "\n",
    "print('Coefficient on CATE prediction:', round(my_drlinear.params[1], 3))\n",
    "print('Standard Error:', round(my_drlinear.bse[1], 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calibration Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_cal_scorer = cal_scorer(drlearner, reg_zero, reg_one, reg_t, 4)\n",
    "res_cal = my_cal_scorer.score(Xval, Dval, yval, Zval, Ztest)\n",
    "\n",
    "df_cal = pd.DataFrame({'gate': res_cal.gate, 'g_cate': res_cal.g_cate,\n",
    "                       'se_gate': res_cal.se_gate})\n",
    "df_cal['95_err'] = 1.96 * df_cal['se_gate']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cal.plot(\n",
    "    kind='scatter',\n",
    "    x='g_cate',\n",
    "    y='gate',\n",
    "    yerr='95_err',\n",
    "    title=f\"Calibration R^2 = {round(res_cal.r_squared_cal, 3)}\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}