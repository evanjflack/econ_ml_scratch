{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib?\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import scipy.special\n",
    "#\n",
    "# np.random.seed(123)\n",
    "# n=2000 # number of raw samples\n",
    "# d=10 # number of binary features + 1\n",
    "#\n",
    "# # Generating random segments aka binary features. We will use features 0,...,3 for heterogeneity.\n",
    "# # The rest for controls. Just as an example.\n",
    "# X = np.random.binomial(1, .5, size=(n, d))\n",
    "# # Generating an imbalanced A/B test\n",
    "# T = np.random.binomial(1, scipy.special.expit(X[:, 0]))\n",
    "# # Generating an outcome with treatment effect heterogeneity. The first binary feature creates heterogeneity\n",
    "# # We also have confounding on the first variable. We also have heteroskedastic errors.\n",
    "# y = (-1 + 2 * X[:, 0]) * T + X[:, 0] + (1*X[:, 0] + 1)*np.random.normal(0, 1, size=(n,))\n",
    "#\n",
    "# X_test = np.random.binomial(1, .5, size=(100, d))\n",
    "# T_test = np.random.binomial(1, scipy.special.expit(X_test[:, 0]))\n",
    "# y_test = (-1 + 2 * X_test[:, 0]) * T_test + X_test[:, 0] + (1*X_test[:, 0] + 1)*np.random.normal(0, 1, size=(100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "time_budget = 600 # time budget for auto-ml in seconds (advisable at least 120)\n",
    "verbose = 0 # verbosity of auto-ml\n",
    "n_splits = 5 # cross-fitting and cross-validation splits\n",
    "data = '401k' # which dataset, one of {'401k', 'criteo', 'welfare', 'poverty', 'star'}\n",
    "plot = True # whether to plot results\n",
    "xfeat = 'inc' # feature to use as x axis in plotting, e.g. for criteo 'f1', for 401k 'inc', for welfare 'polviews'\n",
    "# Formula for the BLP of CATE regression.\n",
    "blp_formula = 'np.log(inc)' # e.g. 'f1' for criteo, np.log(inc)' for 401k, 'C(polviews)' for the welfare case.\n",
    "hetero_feats = ['inc'] # list of subset of features to be used for CATE model or the string 'all' for everything\n",
    "binary_y = False\n",
    "\n",
    "## For semi-synthetic data generation\n",
    "semi_synth = False # Whether true outcome y should be replaced by a fake outcome from a known CEF\n",
    "simple_synth = True # Whether the true CEF of the fake y should be simple or fitted from data\n",
    "max_depth = 2 # max depth of random forest during for semi-synthetic model fitting\n",
    "scale = .2 # magnitude of noise in semi-synthetic data\n",
    "def simple_true_cef(D, X): # simple CEF of the outcome for semi-synthetic data\n",
    "    return .5 * np.array(X)[:, 1] * D + np.array(X)[:, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from datasets import fetch_data_generator\n",
    "\n",
    "get_data, abtest, true_cef, true_cate = fetch_data_generator(data=data, semi_synth=semi_synth,\n",
    "                                                             simple_synth=simple_synth,\n",
    "                                                             scale=scale, true_f=simple_true_cef,\n",
    "                                                             max_depth=max_depth)\n",
    "X, D, y, groups = get_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "if groups is None:\n",
    "    X, Xval, D, Dval, y, yval = train_test_split(X, D, y, train_size=.6, shuffle=True, random_state=123)\n",
    "    Xval, Xtest, Dval, Dtest, yval, ytest = train_test_split(Xval, Dval, yval, train_size=.5, shuffle=True, random_state=123)\n",
    "    groupsval, groupstest = None, None\n",
    "else:\n",
    "    train, val = next(GroupShuffleSplit(n_splits=2, train_size=.6, random_state=123).split(X, y, groups=groups))\n",
    "    X, Xval, D, Dval, y, yval = X.iloc[train], X.iloc[val], D[train], D[val], y[train], y[val]\n",
    "    groups, groupsval = groups[train], groups[val]\n",
    "\n",
    "    val, test = next(GroupShuffleSplit(n_splits=2, train_size=.5, random_state=123).split(Xval, yval, groups=groupsval))\n",
    "    Xval, Xtest, Dval, Dtest, yval, ytest = Xval.iloc[val], Xval.iloc[test], Dval[val], Dval[test], yval[val], yval[test]\n",
    "    groupsval, groupstest = groupsval[val], groupsval[test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from econml.dr import LinearDRLearner\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.dummy import DummyClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Co-variance matrix is underdetermined. Inference will be invalid!\n"
     ]
    },
    {
     "data": {
      "text/plain": "<econml.dr._drlearner.LinearDRLearner at 0x7f85dc710a00>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One can replace model_y and model_t with any scikit-learn regressor and classifier correspondingly\n",
    "# as long as it accepts the sample_weight keyword argument at fit time.\n",
    "est = LinearDRLearner(model_regression=LassoCV(cv=3),\n",
    "                      model_propensity=DummyClassifier(strategy='prior'))\n",
    "est.fit(y, D, X = X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.base import clone"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Xtrain = X[:, :4]\n",
    "# Xval = X_test[:, :4]\n",
    "# Dtrain = T\n",
    "# Dval = T_test\n",
    "# ytrain = y\n",
    "# yval = y_test\n",
    "\n",
    "Xtrain = X\n",
    "Dtrain = D\n",
    "ytrain = y\n",
    "\n",
    "model_reg_zero = est.model_regression\n",
    "model_reg_one = clone(model_reg_zero, safe = False)\n",
    "model_t = est.model_propensity\n",
    "reg_zero = model_reg_zero.fit(Xtrain[Dtrain==0], ytrain[Dtrain==0])\n",
    "reg_one = model_reg_one.fit(Xtrain[Dtrain==1], ytrain[Dtrain==1])\n",
    "reg_zero_preds_t = reg_zero.predict(Xval)\n",
    "reg_one_preds_t = reg_one.predict(Xval)\n",
    "reg_preds_t = reg_zero_preds_t * (1 - Dval) + reg_one_preds_t * Dval\n",
    "prop_preds = model_t.fit(Xtrain, Dtrain).predict(Xval)\n",
    "\n",
    "dr = reg_one_preds_t - reg_zero_preds_t\n",
    "reisz = (Dval - prop_preds) / np.clip(prop_preds * (1 - prop_preds), .09, np.inf)\n",
    "dr += (yval - reg_preds_t) * reisz\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cate_preds = est.fitted_models_final[0].predict(Xval)\n",
    "overall_ate_val_dr = dr.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0007685073901400052"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_val = dr\n",
    "drscore_t = np.mean((dr_val - cate_preds)**2)\n",
    "drscore_b = np.mean((dr_val - overall_ate_val_dr)**2)\n",
    "1 - drscore_t / drscore_b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_zero = model_reg_zero().fit(Xtrain[Dtrain==0], ytrain[Dtrain==0])\n",
    "reg_one = model_reg_one().fit(Xtrain[Dtrain==1], ytrain[Dtrain==1])\n",
    "reg_zero_preds_t = reg_zero.predict(Xval)\n",
    "reg_one_preds_t = reg_one.predict(Xval)\n",
    "reg_preds_t = reg_zero_preds_t * (1 - Dval) + reg_one_preds_t * Dval\n",
    "prop_preds = model_t().fit(Xtrain, Dtrain).predict(Xval)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearDRLearner' object has no attribute 'cate'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcate\u001B[49m(X[:, :\u001B[38;5;241m4\u001B[39m])\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'LinearDRLearner' object has no attribute 'cate'"
     ]
    }
   ],
   "source": [
    "est.cate(X[:, :4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['__abstractmethods__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_abc_impl',\n '_cached_values',\n '_check_fitted_dims',\n '_check_fitted_dims_w_z',\n '_check_input_dims',\n '_d_t',\n '_d_t_in',\n '_d_w',\n '_d_x',\n '_d_y',\n '_d_z',\n '_defer_to_inference',\n '_expand_treatments',\n '_fit_final',\n '_fit_nuisances',\n '_gen_featurizer',\n '_gen_model_final',\n '_gen_ortho_learner_model_final',\n '_gen_ortho_learner_model_nuisance',\n '_get_inference',\n '_get_inference_options',\n '_illegal_refit_inference_methods',\n '_inference',\n '_input_names',\n '_models_nuisance',\n '_original_treatment_featurizer',\n '_ortho_learner_model_final',\n '_ortho_learner_model_nuisance',\n '_postfit',\n '_prefit',\n '_random_state',\n '_set_input_names',\n '_set_transformed_treatment_names',\n '_strata',\n '_subinds_check_none',\n '_use_inference_method',\n '_wrap_fit',\n 'ate',\n 'ate_inference',\n 'ate_interval',\n 'cate_feature_names',\n 'cate_output_names',\n 'cate_treatment_names',\n 'categories',\n 'coef_',\n 'coef__inference',\n 'coef__interval',\n 'const_marginal_ate',\n 'const_marginal_ate_inference',\n 'const_marginal_ate_interval',\n 'const_marginal_effect',\n 'const_marginal_effect_inference',\n 'const_marginal_effect_interval',\n 'cv',\n 'discrete_instrument',\n 'discrete_treatment',\n 'dowhy',\n 'effect',\n 'effect_inference',\n 'effect_interval',\n 'featurizer',\n 'featurizer_',\n 'fit',\n 'fit_cate_intercept',\n 'fit_cate_intercept_',\n 'fitted_models_final',\n 'intercept_',\n 'intercept__inference',\n 'intercept__interval',\n 'marginal_ate',\n 'marginal_ate_inference',\n 'marginal_ate_interval',\n 'marginal_effect',\n 'marginal_effect_inference',\n 'marginal_effect_interval',\n 'mc_agg',\n 'mc_iters',\n 'min_propensity',\n 'model_cate',\n 'model_final',\n 'model_final_',\n 'model_propensity',\n 'model_regression',\n 'models_nuisance_',\n 'models_propensity',\n 'models_regression',\n 'multitask_model_cate',\n 'multitask_model_final',\n 'nuisance_scores_',\n 'nuisance_scores_propensity',\n 'nuisance_scores_regression',\n 'ortho_learner_model_final_',\n 'random_state',\n 'refit_final',\n 'score',\n 'score_',\n 'shap_values',\n 'summary',\n 'transformer',\n 'treatment_featurizer',\n 'z_transformer']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(est)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't call 'ate_interval' because 'inference' is None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 7\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mensemble\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GradientBoostingClassifier, GradientBoostingRegressor\n\u001B[1;32m      4\u001B[0m est \u001B[38;5;241m=\u001B[39m XLearner(models\u001B[38;5;241m=\u001B[39mGradientBoostingRegressor(),\n\u001B[1;32m      5\u001B[0m               propensity_model\u001B[38;5;241m=\u001B[39mGradientBoostingClassifier(),\n\u001B[1;32m      6\u001B[0m               cate_models\u001B[38;5;241m=\u001B[39mGradientBoostingRegressor())\n\u001B[0;32m----> 7\u001B[0m \u001B[43mest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mX\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mate_interval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/my_env/lib/python3.9/site-packages/econml/_cate_estimator.py:917\u001B[0m, in \u001B[0;36mTreatmentExpansionMixin.ate_interval\u001B[0;34m(self, X, T0, T1, alpha)\u001B[0m\n\u001B[1;32m    916\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mate_interval\u001B[39m(\u001B[38;5;28mself\u001B[39m, X\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, T0\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, T1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.05\u001B[39m):\n\u001B[0;32m--> 917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mate_interval\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mT0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mT0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mT1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mT1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/my_env/lib/python3.9/site-packages/econml/_cate_estimator.py:332\u001B[0m, in \u001B[0;36mBaseCateEstimator._defer_to_inference.<locals>.call\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(m)\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 332\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_use_inference_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/my_env/lib/python3.9/site-packages/econml/_cate_estimator.py:327\u001B[0m, in \u001B[0;36mBaseCateEstimator._use_inference_method\u001B[0;34m(self, name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inference, name)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    326\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 327\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt call \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m because \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minference\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is None\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m name)\n",
      "\u001B[0;31mAttributeError\u001B[0m: Can't call 'ate_interval' because 'inference' is None"
     ]
    }
   ],
   "source": [
    "from econml.metalearners import XLearner\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "est = XLearner(models=GradientBoostingRegressor(),\n",
    "              propensity_model=GradientBoostingClassifier(),\n",
    "              cate_models=GradientBoostingRegressor())\n",
    "est.fit(y, T, X=np.hstack([X]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1.45631509, -1.01028833,  1.2851483 , ..., -0.65917494,\n        1.15644912,  0.51027234])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.effect(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[GradientBoostingRegressor(), GradientBoostingRegressor()]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}